{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bfc5ce1",
   "metadata": {},
   "source": [
    "# Feature Importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e0a69c",
   "metadata": {},
   "source": [
    "### Import Packages/Libraries + Data + Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b51b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.data_utils import get_data, get_models, get_feature_lists\n",
    "from src.config import BASE_PATH\n",
    "from src.feat_importance import get_shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fa5a74",
   "metadata": {},
   "source": [
    "Set Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a51a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data\n",
    "OUTCOME_DICT = {\n",
    "    \"surg\": get_data(\"outcome_surg\"),\n",
    "    \"bleed\": get_data(\"outcome_bleed\"),\n",
    "    \"asp\": get_data(\"outcome_asp\"),\n",
    "    \"mort\": get_data(\"outcome_mort\"),\n",
    "}\n",
    "\n",
    "## Models\n",
    "model_dir = BASE_PATH / \"cal_models\"\n",
    "model_prefix_list = [\"lr\", \"lgbm\", \"svc\", \"stack\", \"nn\"]\n",
    "MODEL_DICT = {}\n",
    "for outcome in OUTCOME_DICT.keys():\n",
    "    MODEL_DICT[outcome] = get_models(model_prefix_list, outcome, model_dir)\n",
    "\n",
    "FEAT_ORDER = [\n",
    "    # Pre-op\n",
    "    \"SEX\",  # Nominal\n",
    "    \"RACE\",  # Nominal\n",
    "    \"ETHNICITY_HISPANIC\",  # Binary\n",
    "    \"INOUT\",  # Binary\n",
    "    \"Age\",  # Numerical\n",
    "    \"ELECTSURG\",  # Nominal\n",
    "    \"BMI\",\n",
    "    \"DIABETES\",  # Binary\n",
    "    \"SMOKE\",  # Binary\n",
    "    \"DYSPNEA\",  # Binary\n",
    "    \"FNSTATUS2\",\n",
    "    \"VENTILAT\",\n",
    "    \"HXCOPD\",\n",
    "    \"ASCITES\",\n",
    "    \"HXCHF\",\n",
    "    \"HYPERMED\",\n",
    "    \"RENAFAIL\",\n",
    "    \"DIALYSIS\",\n",
    "    \"DISCANCR\",\n",
    "    \"WNDINF\",\n",
    "    \"STEROID\",\n",
    "    \"WTLOSS\",\n",
    "    \"BLEEDDIS\",\n",
    "    \"TRANSFUS\",\n",
    "    \"PRSEPIS\",\n",
    "    \"PRALBUM\",\n",
    "    \"PRWBC\",\n",
    "    \"ASACLAS\",\n",
    "    # Intra-op\n",
    "    \"OPTIME\",\n",
    "    \"Partial Glossectomy (Hemiglossectomy_Subtotal)\",\n",
    "    \"Composite_Extended Glossectomy\",\n",
    "    \"Total Glossectomy (Complete Tongue Removal)\",\n",
    "    \"Excision of Tongue Lesions (Minor)\",\n",
    "    \"Local_Regional Tissue Flaps for Oral Cavity Reconstruction\",\n",
    "    \"Free Tissue Transfer (Microvascular Free Flaps) and Complex Flap Reconstruction\",\n",
    "    \"Skin Autografts for Head and Neck Reconstruction\",\n",
    "    \"Neck Dissection and Lymphadenectomy Procedures\",\n",
    "    \"Alveolar Ridge and Gingival Procedures\",\n",
    "    \"Mandibular Resection and Reconstruction Procedures\",\n",
    "    \"Peripheral Nerve Repair and Neuroplasty\",\n",
    "    \"Tracheostomy Procedures\",\n",
    "    \"Gastrostomy and Esophageal Access Procedures\",\n",
    "    \"Submandibular Gland Excision\",\n",
    "    \"Parotid Gland Excision\",\n",
    "    \"Laryngeal Resection and Reconstruction Procedures\",\n",
    "    \"Pharyngeal Resection and Reconstruction Procedures\",\n",
    "    \"Tonsillectomy and Tonsillar Region Procedures\",\n",
    "    \"Malignant neoplasm\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f198cd",
   "metadata": {},
   "source": [
    "## SHAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d8d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# import copy\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# import shap\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# def get_ohe_cols(df):\n",
    "#     \"\"\"\n",
    "#     Helper function that returns original column names of features that were one-hot encoded\n",
    "#     Uses '_' as an indicator\n",
    "#     \"\"\"\n",
    "#     ohe_dict = {}\n",
    "#     for col in df.columns:\n",
    "#         col_split = col.split(\"_\")\n",
    "#         if len(col_split) == 1 or col_split[0] in [\n",
    "#             \"ETHNICITY\",\n",
    "#             \"Partial Glossectomy (Hemiglossectomy\",\n",
    "#             \"Composite\",\n",
    "#             \"Local\",\n",
    "#         ]:\n",
    "#             continue\n",
    "#         col_name = col_split[0]\n",
    "#         instance_name = \"_\".join(col_split[1:])\n",
    "#         if col_name in ohe_dict.keys():\n",
    "\n",
    "#             ohe_dict[col_name].append(instance_name)\n",
    "#         else:\n",
    "#             ohe_dict[col_name] = [instance_name]\n",
    "#     return ohe_dict\n",
    "\n",
    "\n",
    "# ######## Combine one-hot-encoded #######\n",
    "# def combine_encoded(shap_values, name, mask, return_original=True):\n",
    "#     \"\"\"\n",
    "#     Helper function to combine shap values for one-hot encoded columns\n",
    "#     Adapted from following repository: https://gist.github.com/peterdhansen/ca87cc1bfbc4c092f0872a3bfe3204b2\n",
    "#     \"\"\"\n",
    "#     mask = np.array(mask)\n",
    "#     mask_col_names = np.array(shap_values.feature_names, dtype=\"object\")[mask]\n",
    "#     sv_name = shap.Explanation(\n",
    "#         shap_values.values[:, mask],\n",
    "#         feature_names=list(mask_col_names),\n",
    "#         data=shap_values.data[:, mask],\n",
    "#         base_values=shap_values.base_values,\n",
    "#         display_data=shap_values.display_data,\n",
    "#         instance_names=shap_values.instance_names,\n",
    "#         output_names=shap_values.output_names,\n",
    "#         output_indexes=shap_values.output_indexes,\n",
    "#         lower_bounds=shap_values.lower_bounds,\n",
    "#         upper_bounds=shap_values.upper_bounds,\n",
    "#         main_effects=shap_values.main_effects,\n",
    "#         hierarchical_values=shap_values.hierarchical_values,\n",
    "#         clustering=shap_values.clustering,\n",
    "#     )\n",
    "#     new_data = (sv_name.data * np.arange(sum(mask))).sum(axis=1).astype(int)  # type: ignore\n",
    "#     svdata = np.concatenate(\n",
    "#         [shap_values.data[:, ~mask], new_data.reshape(-1, 1)], axis=1\n",
    "#     )\n",
    "\n",
    "#     if shap_values.display_data is None:\n",
    "#         svdd = shap_values.data[:, ~mask]\n",
    "#     else:\n",
    "#         svdd = shap_values.display_data[:, ~mask]\n",
    "\n",
    "#     svdisplay_data = np.concatenate(\n",
    "#         [svdd, mask_col_names[new_data].reshape(-1, 1)], axis=1\n",
    "#     )\n",
    "\n",
    "#     # Handle multi-class (3D) vs binary/regression (2D) SHAP arrays\n",
    "#     if len(shap_values.values.shape) == 3:  # Multi-class case\n",
    "#         # Sum encoded features while preserving class dimension\n",
    "#         new_values = sv_name.values.sum(axis=1, keepdims=True)  # type: ignore\n",
    "#         svvalues = np.concatenate([shap_values.values[:, ~mask, :], new_values], axis=1)\n",
    "#     else:  # Binary/regression case\n",
    "#         new_values = sv_name.values.sum(axis=1)  # type: ignore\n",
    "#         svvalues = np.concatenate(\n",
    "#             [shap_values.values[:, ~mask], new_values.reshape(-1, 1)], axis=1\n",
    "#         )\n",
    "\n",
    "#     svfeature_names = list(np.array(shap_values.feature_names)[~mask]) + [name]\n",
    "\n",
    "#     sv = shap.Explanation(\n",
    "#         svvalues,\n",
    "#         base_values=shap_values.base_values,\n",
    "#         data=svdata,\n",
    "#         display_data=svdisplay_data,\n",
    "#         instance_names=shap_values.instance_names,\n",
    "#         feature_names=svfeature_names,\n",
    "#         output_names=shap_values.output_names,\n",
    "#         output_indexes=shap_values.output_indexes,\n",
    "#         lower_bounds=shap_values.lower_bounds,\n",
    "#         upper_bounds=shap_values.upper_bounds,\n",
    "#         main_effects=shap_values.main_effects,\n",
    "#         hierarchical_values=shap_values.hierarchical_values,\n",
    "#         clustering=shap_values.clustering,\n",
    "#     )\n",
    "#     if return_original:\n",
    "#         return sv, sv_name\n",
    "#     else:\n",
    "#         return sv\n",
    "\n",
    "\n",
    "# def get_vals_to_plot(shap_vals):\n",
    "#     \"\"\"\n",
    "#     Helper function to reformat the shap_vals object (return value of shap.explainer())\n",
    "#     \"\"\"\n",
    "#     if len(shap_vals.values.shape) == 3:  # 3D array\n",
    "#         if shap_vals.values.shape[2] == 1:  # Binary classification with single output\n",
    "#             # DNN\n",
    "#             shap_vals_to_plot = shap_vals[:, :, 0]\n",
    "#         elif shap_vals.values.shape[2] >= 2:  # Binary with two outputs or multi-class\n",
    "#             shap_vals_to_plot = shap_vals[:, :, 1]  # Use positive class\n",
    "#         else:\n",
    "#             shap_vals_to_plot = shap_vals.mean(axis=2)  # Fallback\n",
    "#     else:  # 2D array\n",
    "#         # LightGBM, SVC, KNN, Stack, LR-Nomogram\n",
    "#         shap_vals_to_plot = shap_vals\n",
    "#     return shap_vals_to_plot\n",
    "\n",
    "\n",
    "# def generate_MAV(shap_vals, feat_order, model_name, result_path=None):\n",
    "#     \"\"\"\n",
    "#     Helper function to generate and optionally export mean absolute value table for shap values.\n",
    "\n",
    "#     Parameters\n",
    "#     ---------\n",
    "#     shap_vals: shap._explanation.Explanation\n",
    "#         Shap explanation object containing shap values\n",
    "#     feat_order:list[str]\n",
    "#         List of column names specifying desired order in SHAP table\n",
    "#     model_name: str\n",
    "#         Specify which model is being analyzed\n",
    "#     result_path: Optional pathlib.Path; defaults None\n",
    "#         Path to directory where shap tables for all models will be written to\n",
    "#         If left None, will not export\n",
    "#     \"\"\"\n",
    "#     feat_names = shap_vals.feature_names\n",
    "#     try:\n",
    "#         assert set(feat_names) == set(feat_order)\n",
    "#     except AssertionError as e:\n",
    "#         print(f\"Feat name: {len(feat_names)}\")\n",
    "#         print(feat_names)\n",
    "#         print(f\"Feat order: {len(feat_order)}\")\n",
    "#         print(feat_order)\n",
    "#         print(\"ERROR: Feature names does not match feat order\")\n",
    "#         return\n",
    "#     shap_to_plot = get_vals_to_plot(shap_vals)\n",
    "#     shap_df = pd.DataFrame(shap_to_plot.values, columns=feat_names)\n",
    "#     absolute_mean_shap = shap_df.abs().mean().reset_index()\n",
    "#     # Get absolute avg + relative abs avg\n",
    "#     absolute_mean_shap = shap_df.abs().mean().reset_index()\n",
    "#     absolute_mean_shap.columns = [\"Feature\", \"MASV\"]\n",
    "#     sum_vals = absolute_mean_shap[\"MASV\"].sum()\n",
    "#     if sum_vals == 0:\n",
    "#         warnings.warn(\n",
    "#             message=\"All generated SHAP values are 0. Exiting...\", category=Warning\n",
    "#         )\n",
    "#         return\n",
    "#     absolute_mean_shap[\"Relative_ MASV\"] = np.round(\n",
    "#         (100 * absolute_mean_shap[\"MASV\"] / absolute_mean_shap[\"MASV\"].sum()), 2\n",
    "#     )\n",
    "#     # Ensure logic makes sense\n",
    "#     assert np.isclose(\n",
    "#         absolute_mean_shap[\"Relative_ MASV\"].sum(), 100, atol=0.1\n",
    "#     ), f\"Sum is instead {absolute_mean_shap['Relative_ MASV'].sum()}\"\n",
    "#     # Reorder\n",
    "#     absolute_mean_shap[\"Feature\"] = absolute_mean_shap[\"Feature\"].astype(str)\n",
    "\n",
    "#     absolute_mean_shap_reordered = (\n",
    "#         absolute_mean_shap.set_index(\"Feature\").loc[feat_order].reset_index()\n",
    "#     )\n",
    "#     ######################## Display + Export ########################\n",
    "#     if result_path:\n",
    "#         result_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "#         with pd.ExcelWriter(\n",
    "#             result_path,\n",
    "#             engine=\"openpyxl\",\n",
    "#             mode=\"a\" if result_path.exists() else \"w\",\n",
    "#         ) as writer:\n",
    "#             absolute_mean_shap_reordered.to_excel(\n",
    "#                 writer, sheet_name=model_name, index=True\n",
    "#             )\n",
    "\n",
    "\n",
    "# def get_shap(*_, X, model_dict, outcome_name, feat_order, result_path=None):\n",
    "#     \"\"\"\n",
    "#     Generates SHAP values with kernel explainer, builds mean absolute value (MAV) and relative MAV shap tables, and exports the tables\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     X: pandas dataframe\n",
    "#         Tabular dataframe containing data for which SHAP values will be generated (excluding target variable)\n",
    "#         Test set is recommended for useful SHAP values, but can be any subset of the dataset\n",
    "#     model_dict: dict()\n",
    "#         Dictionary mapping model names to models\n",
    "#         Format:\n",
    "#             {\n",
    "#                 <model_name> str: <model> sklearn model\n",
    "#             }\n",
    "#     outcome_name: str\n",
    "#         Specify outcome whose models are being analyzed\n",
    "#     feat_order: list[str]\n",
    "#         List of column names specifying desired order in SHAP table\n",
    "#     result_path: Optional pathlib.Path; defaults None\n",
    "#         Path to directory where shap tables for all models will be written to\n",
    "#         If left None, will not export\n",
    "\n",
    "#     Raises\n",
    "#     ------\n",
    "#     ValueError:\n",
    "#         If positional arguments are provided\n",
    "#     \"\"\"\n",
    "#     if _ != tuple():\n",
    "#         raise ValueError(\"This function does not take positional arguments\")\n",
    "#     if result_path and result_path.exists():\n",
    "#         warnings.warn(\n",
    "#             category=Warning,\n",
    "#             message=f\"Removing file at {result_path}. \\nUnless this function fails, will over-write with new SHAP table\",\n",
    "#         )\n",
    "#         result_path.unlink()\n",
    "#     ######################## Get SHAP values ########################\n",
    "#     for model_name, model in model_dict.items():\n",
    "#         print(f\"Working on model: {model_name}...\")\n",
    "#         explainer = shap.Explainer(\n",
    "#             model.predict_proba, X, feature_names=X.columns.tolist()\n",
    "#         )\n",
    "#         shap_raw = explainer(X)\n",
    "#         ######################## Deal with one-hot encoded ########################\n",
    "#         ohe_dict = get_ohe_cols(X)\n",
    "#         ohe_cols = ohe_dict.keys()\n",
    "#         ### Get OHE feature order for raw\n",
    "#         raw_feat_order = []\n",
    "#         for col in feat_order:\n",
    "#             if col in ohe_cols:\n",
    "#                 for sub_col in ohe_dict[col]:\n",
    "#                     raw_feat_order.append(f\"{col}_{sub_col}\")\n",
    "#             else:\n",
    "#                 raw_feat_order.append(col)\n",
    "#         ### Combine ohe for combined\n",
    "#         shap_old = copy.deepcopy(shap_raw)\n",
    "#         for col_name in ohe_cols:\n",
    "#             shap_combined, _ = combine_encoded(\n",
    "#                 shap_old, col_name, [col_name in n for n in shap_old.feature_names]\n",
    "#             )\n",
    "#             shap_old = shap_combined\n",
    "#         ######################## Generate + export MAV table ########################\n",
    "#         if result_path:\n",
    "#             raw_path = result_path / \"raw\" / f\"{outcome_name}.xlsx\"\n",
    "#             combined_path = result_path / \"combined\" / f\"{outcome_name}.xlsx\"\n",
    "#         else:\n",
    "#             raw_path = None\n",
    "#             combined_path = None\n",
    "#         generate_MAV(\n",
    "#             shap_raw, raw_feat_order, model_name=model_name, result_path=raw_path\n",
    "#         )\n",
    "#         generate_MAV(\n",
    "#             shap_combined, feat_order, model_name=model_name, result_path=combined_path\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for outcome_name, outcome_data in OUTCOME_DICT.items():\n",
    "    print(f\"{'-'*40} {outcome_name} {'-'*40}\")\n",
    "    cur_model_dict = MODEL_DICT[outcome_name]\n",
    "    X = outcome_data[\"X_test\"]\n",
    "    feat_lists = get_feature_lists(X)\n",
    "    for idx, col in enumerate(FEAT_ORDER):\n",
    "        if col not in feat_lists[\"nominal_cols\"]:\n",
    "            continue\n",
    "\n",
    "    get_shap(\n",
    "        X=X,\n",
    "        model_dict=cur_model_dict,\n",
    "        outcome_name=outcome_name,\n",
    "        feat_order=FEAT_ORDER,\n",
    "        result_path=BASE_PATH / \"results\" / \"tables\" / \"SHAP\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
