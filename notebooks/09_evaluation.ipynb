{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f566bc6",
   "metadata": {},
   "source": [
    "# Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fffe5b",
   "metadata": {},
   "source": [
    "### Import Packages/Libraries + Data + Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaba77f",
   "metadata": {},
   "source": [
    "Import libraries/packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae85422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.data_utils import get_data, get_models\n",
    "from src.evaluate import evaluate_models\n",
    "from src.config import BASE_PATH\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c5982",
   "metadata": {},
   "source": [
    "Set Globals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af7954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = BASE_PATH / \"results\"\n",
    "\n",
    "##Data\n",
    "OUTCOME_DICT = {\n",
    "    \"surg\": get_data(\"outcome_surg\"),\n",
    "    \"bleed\": get_data(\"outcome_bleed\"),\n",
    "    \"asp\": get_data(\"outcome_asp\"),\n",
    "    \"mort\": get_data(\"outcome_mort\"),\n",
    "}\n",
    "\n",
    "##Models\n",
    "model_prefix_list = [\"lr\", \"lgbm\", \"svc\", \"stack\", \"nn\"]\n",
    "model_dir = BASE_PATH / \"cal_models\"\n",
    "MODEL_DICT = {}\n",
    "for outcome in OUTCOME_DICT.keys():\n",
    "    MODEL_DICT[outcome] = get_models(model_prefix_list, outcome, file_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467a7007",
   "metadata": {},
   "source": [
    "Import base models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b4b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.nn_models import load_nn_clf\n",
    "# import torch\n",
    "# DEVICE = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "# model_prefix_list = ['lr', 'lgbm', 'svc', 'stack']\n",
    "# ##Can use any X df for input dimension, all = # of features\n",
    "# nn_in_dim = OUTCOME_DICT['surg']['X_train'].shape[1]\n",
    "# model_dir = '../models'\n",
    "# MODEL_DICT = {}\n",
    "# for outcome in OUTCOME_DICT.keys():\n",
    "#     MODEL_DICT[outcome] = get_models(model_prefix_list, outcome)\n",
    "#     MODEL_DICT[outcome]['nn'] = load_nn_clf(data_path= f'{model_dir}/{outcome}/nn.pt',\n",
    "#                                             in_dim=nn_in_dim,\n",
    "#                                             device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94d5b01",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "1. AUROC\n",
    "   - Train vs validation vs test plot\n",
    "   - 95% CI\n",
    "2. Confusion Matrices\n",
    "3. Discrimination Values (w/ 95% CIs)\n",
    "   - Accuracy\n",
    "   - f1\n",
    "   - recall\n",
    "   - precision\n",
    "4. Calibration\n",
    "   - Calibration Curves\n",
    "   - ICC (w/ 95% CIs)\n",
    "   - brier score (w/ 95% CIs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59968013",
   "metadata": {},
   "outputs": [],
   "source": [
    "for outcome, cur_data in OUTCOME_DICT.items():\n",
    "    print(f\"{'*' *30} Outcome: {outcome} {'*' *30}\")\n",
    "    cur_models_dict = MODEL_DICT[outcome]\n",
    "    class_report_dict = evaluate_models(\n",
    "        model_dict=cur_models_dict,\n",
    "        outcome_name=outcome,\n",
    "        X_train=cur_data[\"X_train\"],\n",
    "        y_train=cur_data[\"y_train\"].values.ravel(),\n",
    "        X_val=cur_data[\"X_val\"],\n",
    "        y_val=cur_data[\"y_val\"].values.ravel(),\n",
    "        X_test=cur_data[\"X_test\"],\n",
    "        y_test=cur_data[\"y_test\"].values.ravel(),\n",
    "        results_path=SAVE_PATH,\n",
    "        threshold_str=\"val\",\n",
    "        show_cm=False,\n",
    "        show_roc=False,\n",
    "        show_cal=False,\n",
    "    )\n",
    "    for ds, report_per_model in class_report_dict.items():\n",
    "        model_report_df = pd.DataFrame(report_per_model).T\n",
    "        report_path = SAVE_PATH / \"tables\" / \"class_report\" / outcome / f\"{ds}.csv\"\n",
    "        if report_path.exists():\n",
    "            warnings.warn(f\"Over-writing class report table at path: {report_path}\")\n",
    "            report_path.unlink()\n",
    "        report_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "        model_report_df.to_csv(report_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
