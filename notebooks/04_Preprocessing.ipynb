{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4c5cd7",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2845e88",
   "metadata": {},
   "source": [
    "## Set globals + initial cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9618d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.data_utils import get_feature_lists\n",
    "from src.config import SEED, BASE_PATH\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from src.preprocess import BMICalculatorArray, transform_export_data\n",
    "\n",
    "outcome_df = pd.read_excel(\n",
    "    BASE_PATH / \"data\" / \"processed\" / \"Outcome_df.xlsx\", index_col=0\n",
    ")\n",
    "X_df = pd.read_excel(\n",
    "    BASE_PATH / \"data\" / \"processed\" / \"fully_cleaned_tongue_data.xlsx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847bd478",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = [\n",
    "    # Pre-op\n",
    "    \"SEX\",  # Nominal\n",
    "    \"RACE_NEW\",  # Nominal\n",
    "    \"ETHNICITY_HISPANIC\",  # Binary\n",
    "    \"INOUT\",  # Binary\n",
    "    \"Age\",  # Numerical\n",
    "    \"URGENCY\",  # Nominal\n",
    "    \"HEIGHT\",  # Numerical\n",
    "    \"WEIGHT\",  # Numerical\n",
    "    \"DIABETES\",  # Binary\n",
    "    \"SMOKE\",  # Binary\n",
    "    \"DYSPNEA\",  # Binary\n",
    "    \"FNSTATUS2\",\n",
    "    \"VENTILAT\",\n",
    "    \"HXCOPD\",\n",
    "    \"ASCITES\",\n",
    "    \"HXCHF\",\n",
    "    \"HYPERMED\",\n",
    "    \"RENAFAIL\",\n",
    "    \"DIALYSIS\",\n",
    "    \"DISCANCR\",\n",
    "    \"WNDINF\",\n",
    "    \"STEROID\",\n",
    "    \"WTLOSS\",\n",
    "    \"BLEEDDIS\",\n",
    "    \"TRANSFUS\",\n",
    "    \"PRSEPIS\",\n",
    "    \"PRALBUM\",\n",
    "    \"PRWBC\",\n",
    "    \"PRHCT\",\n",
    "    \"PRPLATE\",\n",
    "    \"ASACLAS\",\n",
    "    \"OPERYR\",\n",
    "    # Intra-op\n",
    "    \"OPTIME\",\n",
    "    \"Partial Glossectomy (Hemiglossectomy_Subtotal)\",\n",
    "    \"Composite_Extended Glossectomy\",\n",
    "    \"Total Glossectomy (Complete Tongue Removal)\",\n",
    "    \"Excision of Tongue Lesions (Minor)\",\n",
    "    \"Local_Regional Tissue Flaps for Oral Cavity Reconstruction\",\n",
    "    \"Free Tissue Transfer (Microvascular Free Flaps) and Complex Flap Reconstruction\",\n",
    "    \"Skin Autografts for Head and Neck Reconstruction\",\n",
    "    \"Neck Dissection and Lymphadenectomy Procedures\",\n",
    "    \"Alveolar Ridge and Gingival Procedures\",\n",
    "    \"Mandibular Resection and Reconstruction Procedures\",\n",
    "    \"Peripheral Nerve Repair and Neuroplasty\",\n",
    "    \"Tracheostomy Procedures\",\n",
    "    \"Gastrostomy and Esophageal Access Procedures\",\n",
    "    \"Submandibular Gland Excision\",\n",
    "    \"Parotid Gland Excision\",\n",
    "    \"Laryngeal Resection and Reconstruction Procedures\",\n",
    "    \"Pharyngeal Resection and Reconstruction Procedures\",\n",
    "    \"Tonsillectomy and Tonsillar Region Procedures\",\n",
    "    \"Malignant neoplasm\",\n",
    "]\n",
    "x_cols_cap = [col.upper() for col in x_cols]\n",
    "X_sub = X_df[x_cols_cap].copy()\n",
    "X_sub.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6a91e2",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef228bb8",
   "metadata": {},
   "source": [
    "Initialize feature types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Imported func from src\n",
    "feature_lists = get_feature_lists(X_sub)\n",
    "binary_cols = feature_lists[\"binary_cols\"]\n",
    "numerical_cols = feature_lists[\"numerical_cols\"]\n",
    "nominal_cols = feature_lists[\"nominal_cols\"]\n",
    "ordinal_cols = feature_lists[\"ordinal_cols\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {\n",
    "    \"SEX\": {\"male\": \"1\", \"female\": \"0\"},\n",
    "    \"URGENCY\": {\"Urgent_Emergent\": \"1\", \"Elective\": \"0\"},\n",
    "    \"ETHNICITY_HISPANIC\": {\"noUnknown\": \"0\", \"Yes\": \"1\"},\n",
    "}\n",
    "replace_w_binary_cols = [col for col in binary_cols if \"Yes\" in X_sub[col].unique()]\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\n",
    "        \"ignore\", category=FutureWarning, message=\".*Downcasting behavior.*\"\n",
    "    )\n",
    "    X_sub = X_sub.replace(replace_dict).infer_objects(copy=False).copy()\n",
    "    X_sub[replace_w_binary_cols] = (\n",
    "        X_sub[replace_w_binary_cols]\n",
    "        .replace({\"Yes\": 1, \"No\": 0})\n",
    "        .infer_objects(copy=False)\n",
    "        .copy()\n",
    "    )\n",
    "assert (\n",
    "    len(binary_cols) + len(nominal_cols) + len(ordinal_cols) + len(numerical_cols)\n",
    "    == X_sub.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a288006",
   "metadata": {},
   "source": [
    "Construct Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wnd_class_order = ['1-Clean', '2-Clean/Contaminated', '3-Contaminated', '4-Dirty/Infected']\n",
    "asa_class_order = [\n",
    "    \"1-No Disturb\",\n",
    "    \"2-Mild Disturb\",\n",
    "    \"3-Severe Disturb\",\n",
    "    \"4/5-Life Threat/Moribund\",\n",
    "]\n",
    "\n",
    "height_idx = numerical_cols.index(\"HEIGHT\")\n",
    "weight_idx = numerical_cols.index(\"WEIGHT\")\n",
    "\n",
    "# Numerical pipeline: Impute, calculate BMI, then scale\n",
    "num_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"imputer\",\n",
    "            IterativeImputer(\n",
    "                estimator=None,  # default = BayesianRidge\n",
    "                initial_strategy=\"median\",\n",
    "                max_iter=10,\n",
    "                sample_posterior=False,  # deterministic\n",
    "            ),\n",
    "        ),\n",
    "        (\"bmi\", BMICalculatorArray(height_idx=height_idx, weight_idx=weight_idx)),\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Categorical pipeline: OneHotEncode\n",
    "nom_pipeline = Pipeline([(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "# Ordinal Pipeline for asa class\n",
    "asa_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"encoder\",\n",
    "            OrdinalEncoder(\n",
    "                categories=[asa_class_order],\n",
    "                handle_unknown=\"use_encoded_value\",\n",
    "                unknown_value=-1,\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combine all preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", num_pipeline, numerical_cols),\n",
    "        (\"cat\", nom_pipeline, nominal_cols),\n",
    "        # ('ord_wnd', wnd_pipeline, [ordinal_cols[0]]),\n",
    "        (\"ord_asa\", asa_pipeline, [ordinal_cols[0]]),\n",
    "        (\"bin\", \"passthrough\", binary_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d7da1b",
   "metadata": {},
   "source": [
    "Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b2d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = BASE_PATH / \"data\" / \"processed\"\n",
    "pipeline_path = BASE_PATH / \"data\" / \"preprocessors\"\n",
    "# 8.4% positive distribution\n",
    "surg_data = transform_export_data(\n",
    "    X_sub,\n",
    "    outcome_df[\"Surgical_Outcome\"],\n",
    "    \"outcome_surg\",\n",
    "    preprocessor,\n",
    "    data_path,\n",
    "    pipeline_path,\n",
    ")\n",
    "# 10% positive distribution\n",
    "bleed_data = transform_export_data(\n",
    "    X_sub,\n",
    "    outcome_df[\"Bleed_Outcome\"],\n",
    "    \"outcome_bleed\",\n",
    "    preprocessor,\n",
    "    data_path,\n",
    "    pipeline_path,\n",
    ")\n",
    "# 7.05% positive distribution\n",
    "asp_data = transform_export_data(\n",
    "    X_sub,\n",
    "    outcome_df[\"Aspiration_Outcome\"],\n",
    "    \"outcome_asp\",\n",
    "    preprocessor,\n",
    "    data_path,\n",
    "    pipeline_path,\n",
    ")\n",
    "# 0.9% positive distribution\n",
    "mort_data = transform_export_data(\n",
    "    X_sub,\n",
    "    outcome_df[\"Mortality_Outcome\"],\n",
    "    \"outcome_mort\",\n",
    "    preprocessor,\n",
    "    data_path,\n",
    "    pipeline_path,\n",
    ")\n",
    "# 8.5% positive distribution\n",
    "mort_data = transform_export_data(\n",
    "    X_sub,\n",
    "    outcome_df[\"ReOp_Outcome\"],\n",
    "    \"outcome_reop\",\n",
    "    preprocessor,\n",
    "    data_path,\n",
    "    pipeline_path,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-tongue-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
